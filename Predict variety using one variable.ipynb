{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68220, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wine_review_top10_variety.csv',index_col = 0)\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html.parser\n",
      "Requirement already satisfied: ply in /anaconda3/lib/python3.6/site-packages (from html.parser) (3.11)\n",
      "Installing collected packages: html.parser\n",
      "Successfully installed html.parser\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pattern3 in /anaconda3/lib/python3.6/site-packages (3.0.0)\n",
      "Requirement already satisfied: feedparser in /anaconda3/lib/python3.6/site-packages (from pattern3) (5.2.1)\n",
      "Requirement already satisfied: pdfminer.six in /anaconda3/lib/python3.6/site-packages (from pattern3) (20181108)\n",
      "Requirement already satisfied: cherrypy in /anaconda3/lib/python3.6/site-packages (from pattern3) (18.1.1)\n",
      "Requirement already satisfied: pdfminer3k in /anaconda3/lib/python3.6/site-packages (from pattern3) (1.3.1)\n",
      "Requirement already satisfied: simplejson in /anaconda3/lib/python3.6/site-packages (from pattern3) (3.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /anaconda3/lib/python3.6/site-packages (from pattern3) (4.6.0)\n",
      "Requirement already satisfied: docx in /anaconda3/lib/python3.6/site-packages (from pattern3) (0.2.4)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (1.11.0)\n",
      "Requirement already satisfied: sortedcontainers in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (1.5.10)\n",
      "Requirement already satisfied: pycryptodome in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (3.8.1)\n",
      "Requirement already satisfied: more-itertools in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (4.1.0)\n",
      "Requirement already satisfied: portend>=2.1.1 in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (2.3)\n",
      "Requirement already satisfied: cheroot>=6.2.4 in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (6.5.4)\n",
      "Requirement already satisfied: zc.lockfile in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (1.4)\n",
      "Requirement already satisfied: pytest>=2.0 in /anaconda3/lib/python3.6/site-packages (from pdfminer3k->pattern3) (3.5.1)\n",
      "Requirement already satisfied: ply>=3.4 in /anaconda3/lib/python3.6/site-packages (from pdfminer3k->pattern3) (3.11)\n",
      "Requirement already satisfied: lxml in /anaconda3/lib/python3.6/site-packages (from docx->pattern3) (4.2.1)\n",
      "Requirement already satisfied: Pillow>=2.0 in /anaconda3/lib/python3.6/site-packages (from docx->pattern3) (5.1.0)\n",
      "Requirement already satisfied: tempora>=1.8 in /anaconda3/lib/python3.6/site-packages (from portend>=2.1.1->cherrypy->pattern3) (1.14)\n",
      "Requirement already satisfied: backports.functools-lru-cache in /anaconda3/lib/python3.6/site-packages (from cheroot>=6.2.4->cherrypy->pattern3) (1.5)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from zc.lockfile->cherrypy->pattern3) (39.1.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (1.5.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (18.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (0.6.0)\n",
      "Requirement already satisfied: pytz in /anaconda3/lib/python3.6/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2018.4)\n",
      "Requirement already satisfied: jaraco.functools>=1.20 in /anaconda3/lib/python3.6/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2.0)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pyLDAvis in /anaconda3/lib/python3.6/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.14.3)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.31.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (2.10)\n",
      "Requirement already satisfied: numexpr in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (2.6.5)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: pytest in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (3.5.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: funcy in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.11)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /anaconda3/lib/python3.6/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.5.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (39.1.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (18.1.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (4.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /anaconda3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2018.4)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Original:   [\"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\", \"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\"] \n",
      "\n",
      "Processed:  ['circus dog plisse skirt jump python large foot long', 'circus dog plisse skirt jump python large foot long']\n"
     ]
    }
   ],
   "source": [
    "%run ./Text_Normalization_Function.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_description = normalize_corpus(df.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW TEXT:  Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of honey-drizzled guava and mango giving way to a slightly astringent, semidry finish.\n",
      "\n",
      "NORMALIZED TEXT:  pineapple rind lemon pith orange blossom start aroma palate bit opulent note honey drizzled guava mango give way slightly astringent semidry finish\n"
     ]
    }
   ],
   "source": [
    "print('RAW TEXT: ', np.array(df.description)[0])\n",
    "print()\n",
    "print('NORMALIZED TEXT: ', norm_description[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description']=norm_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Riesling', 'Pinot Noir', 'Cabernet Sauvignon', 'Chardonnay',\n",
       "       'Red Blend', 'Sauvignon Blanc', 'Bordeaux-style Red Blend', 'Rosé',\n",
       "       'Syrah'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names=df['variety'].unique()\n",
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please seperate the data into test dataset and training dataset up to this point.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_with_words(df):\n",
    "    def get_train_test(df):\n",
    "        test=df.sample(n=13700, replace=False,axis=0)\n",
    "        test_bunch['data']=test['description']\n",
    "        test_bunch['target']=test['variety']\n",
    "        train=df.drop(axis=0, index=test.index)\n",
    "        train_bunch['data']=train['description']\n",
    "        train_bunch['target']=train['variety']\n",
    "    \n",
    "        return test_bunch,train_bunch\n",
    "    test_bunch={'data':[],'target':[]}\n",
    "    train_bunch={'data':[],'target':[]}\n",
    "    test,train=get_train_test(df)\n",
    "    \n",
    "    ## BOW train!!\n",
    "    vectorizer_bow = CountVectorizer(stop_words = 'english') \n",
    "    feature_matrix_bow = vectorizer_bow.fit_transform(train['data']).astype(float) # replace norm_description by your training data\n",
    "    \n",
    "    # 2-gram train!!!\n",
    "    vectorizer_2grams = TfidfVectorizer(ngram_range = (2,2)) \n",
    "    feature_matrix_2grams = vectorizer_2grams.fit_transform(train['data']).astype(float) # replace norm_description by your training data\n",
    "    \n",
    "    # 3-gram train!!!\n",
    "    vectorizer_3grams = TfidfVectorizer(ngram_range = (3,3)) \n",
    "    feature_matrix_3grams = vectorizer_3grams.fit_transform(train['data']).astype(float) # replace norm_description by your training data\n",
    "    \n",
    "    # for this part, please fit the testdata\n",
    "    feature_matrix_TEST_bow = vectorizer_bow.transform(test['data'])\n",
    "    feature_matrix_TEST_2grams = vectorizer_2grams.transform(test['data'])\n",
    "    feature_matrix_TEST_3grams = vectorizer_3grams.transform(test['data'])\n",
    "    \n",
    "    return test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of using 2 grams: \n",
      " 0.736934306569343\n",
      "Accuracy rate of using 3 grams: \n",
      " 0.6989270072992702\n",
      "Accuracy rate of using bag of words: \n",
      " 0.7715255474452555\n"
     ]
    }
   ],
   "source": [
    "accuracy_2grams=[]\n",
    "accuracy_3grams=[]\n",
    "accuracy_bow=[]\n",
    "for i in range (0,10):\n",
    "    test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams=train_test_with_words(df)\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    #Naive Bayes\n",
    "\n",
    "    #using 2 grams\n",
    "    clf_2grams = MultinomialNB(alpha=0.1) \n",
    "    clf_2grams.fit(feature_matrix_2grams, train['target'])\n",
    "    predicted_nb_2grams = clf_2grams.predict(feature_matrix_TEST_2grams)\n",
    "    cm_2grams = metrics.confusion_matrix(test['target'], predicted_nb_2grams)\n",
    "    #Confusion_matrix=pd.DataFrame(data = cm, columns = target_names,index = target_names)\n",
    "    accuracy_2grams.append(metrics.accuracy_score(test['target'], predicted_nb_2grams))\n",
    "    \n",
    "    #using 3 grams\n",
    "    clf_3grams = MultinomialNB(alpha=0.1) \n",
    "    clf_3grams.fit(feature_matrix_3grams, train['target'])\n",
    "    predicted_nb_3grams = clf_3grams.predict(feature_matrix_TEST_3grams)\n",
    "    cm_3grams = metrics.confusion_matrix(test['target'], predicted_nb_3grams)\n",
    "    accuracy_3grams.append(metrics.accuracy_score(test['target'], predicted_nb_3grams))\n",
    "    \n",
    "    #using bag of words\n",
    "    clf_bow = MultinomialNB(alpha=0.1) \n",
    "    clf_bow.fit(feature_matrix_bow, train['target'])\n",
    "    predicted_nb_bow = clf_bow.predict(feature_matrix_TEST_bow)\n",
    "    cm_bow = metrics.confusion_matrix(test['target'], predicted_nb_bow)\n",
    "    accuracy_bow.append(metrics.accuracy_score(test['target'], predicted_nb_bow))\n",
    "\n",
    "print(\"Accuracy rate of using 2 grams: \\n\", np.mean(list(accuracy_2grams))) \n",
    "print(\"Accuracy rate of using 3 grams: \\n\", np.mean(list(accuracy_3grams))) \n",
    "print(\"Accuracy rate of using bag of words: \\n\", np.mean(list(accuracy_bow))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of using 2 grams: \n",
      " 0.6605839416058394\n",
      "Accuracy rate of using 3 grams: \n",
      " 0.48320437956204376\n",
      "Accuracy rate of using bag of words: \n",
      " 0.8223941605839415\n"
     ]
    }
   ],
   "source": [
    "accuracy_2grams=[]\n",
    "accuracy_3grams=[]\n",
    "accuracy_bow=[]\n",
    "for i in range (0,10):\n",
    "    test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams=train_test_with_words(df)\n",
    "    from sklearn import linear_model\n",
    "    \n",
    "    #Logit Regression\n",
    "\n",
    "    #using 2 grams\n",
    "    clf_2grams = linear_model.SGDClassifier(loss='log') \n",
    "    clf_2grams.fit(feature_matrix_2grams, train['target'])\n",
    "    predicted_nb_2grams = clf_2grams.predict(feature_matrix_TEST_2grams)\n",
    "    cm_2grams = metrics.confusion_matrix(test['target'], predicted_nb_2grams)\n",
    "    #Confusion_matrix=pd.DataFrame(data = cm, columns = target_names,index = target_names)\n",
    "    accuracy_2grams.append(metrics.accuracy_score(test['target'], predicted_nb_2grams))\n",
    "    \n",
    "    #using 3 grams\n",
    "    clf_3grams = linear_model.SGDClassifier(loss='log') \n",
    "    clf_3grams.fit(feature_matrix_3grams, train['target'])\n",
    "    predicted_nb_3grams = clf_3grams.predict(feature_matrix_TEST_3grams)\n",
    "    cm_3grams = metrics.confusion_matrix(test['target'], predicted_nb_3grams)\n",
    "    accuracy_3grams.append(metrics.accuracy_score(test['target'], predicted_nb_3grams))\n",
    "    \n",
    "    #using bag of words \n",
    "    clf_bow = linear_model.SGDClassifier(loss='log') \n",
    "    clf_bow.fit(feature_matrix_bow, train['target'])\n",
    "    predicted_nb_bow = clf_bow.predict(feature_matrix_TEST_bow)\n",
    "    cm_bow = metrics.confusion_matrix(test['target'], predicted_nb_bow)\n",
    "    accuracy_bow.append(metrics.accuracy_score(test['target'], predicted_nb_bow))\n",
    "\n",
    "print(\"Accuracy rate of using 2 grams: \\n\", np.mean(list(accuracy_2grams))) \n",
    "print(\"Accuracy rate of using 3 grams: \\n\", np.mean(list(accuracy_3grams))) \n",
    "print(\"Accuracy rate of using bag of words: \\n\", np.mean(list(accuracy_bow))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of using 2 grams: \n",
      " 0.7590510948905109\n",
      "Accuracy rate of using 3 grams: \n",
      " 0.6987591240875912\n",
      "Accuracy rate of using bag of words: \n",
      " 0.8132919708029197\n"
     ]
    }
   ],
   "source": [
    "accuracy_2grams=[]\n",
    "accuracy_3grams=[]\n",
    "accuracy_bow=[]\n",
    "for i in range (0,10):\n",
    "    test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams=train_test_with_words(df)\n",
    "    from sklearn import linear_model\n",
    "    \n",
    "    #SVM \n",
    "\n",
    "    #using 2 grams\n",
    "    clf_2grams = linear_model.SGDClassifier(loss='hinge') \n",
    "    clf_2grams.fit(feature_matrix_2grams, train['target'])\n",
    "    predicted_nb_2grams = clf_2grams.predict(feature_matrix_TEST_2grams)\n",
    "    cm_2grams = metrics.confusion_matrix(test['target'], predicted_nb_2grams)\n",
    "    #Confusion_matrix=pd.DataFrame(data = cm, columns = target_names,index = target_names)\n",
    "    accuracy_2grams.append(metrics.accuracy_score(test['target'], predicted_nb_2grams))\n",
    "    \n",
    "    #using 3 grams\n",
    "    clf_3grams = linear_model.SGDClassifier(loss='hinge') \n",
    "    clf_3grams.fit(feature_matrix_3grams, train['target'])\n",
    "    predicted_nb_3grams = clf_3grams.predict(feature_matrix_TEST_3grams)\n",
    "    cm_3grams = metrics.confusion_matrix(test['target'], predicted_nb_3grams)\n",
    "    accuracy_3grams.append(metrics.accuracy_score(test['target'], predicted_nb_3grams))\n",
    "    \n",
    "    #using bag of words \n",
    "    clf_bow = linear_model.SGDClassifier(loss='hinge') \n",
    "    clf_bow.fit(feature_matrix_bow, train['target'])\n",
    "    predicted_nb_bow = clf_bow.predict(feature_matrix_TEST_bow)\n",
    "    cm_bow = metrics.confusion_matrix(test['target'], predicted_nb_bow)\n",
    "    accuracy_bow.append(metrics.accuracy_score(test['target'], predicted_nb_bow))\n",
    "\n",
    "print(\"Accuracy rate of using 2 grams: \\n\", np.mean(list(accuracy_2grams))) \n",
    "print(\"Accuracy rate of using 3 grams: \\n\", np.mean(list(accuracy_3grams))) \n",
    "print(\"Accuracy rate of using bag of words: \\n\", np.mean(list(accuracy_bow))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
