{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>winery</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Domaine Zind-Humbrecht</td>\n",
       "      <td>Rich gold in color. Broad, layered aromas of v...</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Testarossa</td>\n",
       "      <td>Cooked cranberry is spiced with anise, pepperc...</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Robert Mondavi</td>\n",
       "      <td>Pithy, with grapefruit and lemon peel flavors,...</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Testarossa</td>\n",
       "      <td>Overly sweet and simple, and something of a di...</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Robert Mondavi</td>\n",
       "      <td>With rich, sweet blackberry and cocoa flavors,...</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                  winery  \\\n",
       "0      0  Domaine Zind-Humbrecht   \n",
       "1      1              Testarossa   \n",
       "2      2          Robert Mondavi   \n",
       "3      3              Testarossa   \n",
       "4      4          Robert Mondavi   \n",
       "\n",
       "                                         description  points price  \n",
       "0  Rich gold in color. Broad, layered aromas of v...      90     3  \n",
       "1  Cooked cranberry is spiced with anise, pepperc...      91     3  \n",
       "2  Pithy, with grapefruit and lemon peel flavors,...      90     1  \n",
       "3  Overly sweet and simple, and something of a di...      85     2  \n",
       "4  With rich, sweet blackberry and cocoa flavors,...      87     2  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('top_24_winery.csv',index_col = 0)\n",
    "df = df[~df.price.isnull()].reset_index()\n",
    "df.head()\n",
    "\n",
    "def returnprice(price):\n",
    "    if price<=20:\n",
    "        return 'low'\n",
    "    elif price<=50:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "df['price']=df['price'].apply(returnprice).map({'low':1,'medium':2,'high':3}).astype('category')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4160 entries, 0 to 4159\n",
      "Data columns (total 5 columns):\n",
      "index          4160 non-null int64\n",
      "winery         4160 non-null object\n",
      "description    4160 non-null object\n",
      "points         4160 non-null int64\n",
      "price          4160 non-null category\n",
      "dtypes: category(1), int64(2), object(2)\n",
      "memory usage: 134.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\Erin' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n",
      "'C:\\Users\\Erin' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n",
      "'C:\\Users\\Erin' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Original:   [\"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\", \"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\"] \n",
      "\n",
      "Processed:  ['circus dog plisse skirt jump python large foot long', 'circus dog plisse skirt jump python large foot long']\n"
     ]
    }
   ],
   "source": [
    "%run ./Text_Normalization_Function.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_description = normalize_corpus(df.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW TEXT:  Rich gold in color. Broad, layered aromas of very ripe fruit with hints of sweet smoke, brown sugar, honey and a savory earthy minerality. Full-bodied, bone dry, but richly textured with crisp acidity and a wide palette of flavors, ripe stone fruit, a creamy savory earthiness, sage and a balsamic kick on the finish. Very long length, slightly warm but with a lingering savory, mineral finish.\n",
      "\n",
      "NORMALIZED TEXT:  rich gold color broad layer aroma ripe fruit hint sweet smoke brown sugar honey savory earthy minerality full bodied bone dry richly textured crisp acidity wide palette flavor ripe stone fruit creamy savory earthiness sage balsamic kick finish long length slightly warm linger savory mineral finish\n"
     ]
    }
   ],
   "source": [
    "print('RAW TEXT: ', np.array(df.description)[0])\n",
    "print()\n",
    "print('NORMALIZED TEXT: ', norm_description[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description']=norm_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Domaine Zind-Humbrecht', 'Testarossa', 'Robert Mondavi',\n",
       "       'Louis Latour', 'Undurraga', 'Chehalem', 'Iron Horse', 'Foxen',\n",
       "       'Chateau Ste. Michelle', 'Wines & Winemakers', 'Georges Duboeuf',\n",
       "       'Maryhill', 'Fess Parker', 'Santa Ema', 'Kendall-Jackson',\n",
       "       'Williams Selyem', 'Concha y Toro', 'Trapiche',\n",
       "       'Feudi di San Gregorio', 'Louis Jadot', 'DFJ Vinhos', 'V. Sattui',\n",
       "       'Columbia Crest', 'Montes', 'Casa Santos Lima',\n",
       "       'Chanson Père et Fils', 'Bründlmayer', 'Lynmar', 'Siduri', 'Kunde',\n",
       "       'Gary Farrell', 'Jean-Luc and Paul Aegerter', 'Albert Bichot'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names=df['winery'].unique()\n",
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please seperate the data into test dataset and training dataset up to this point.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_with_words(df):\n",
    "    def get_train_test(df):\n",
    "        test=df.sample(n=887, replace=False,axis=0)\n",
    "        test_bunch['data']=test['description']\n",
    "        test_bunch['target']=test['winery']\n",
    "        test_bunch['price']=test['price']\n",
    "        train=df.drop(axis=0, index=test.index)\n",
    "        train_bunch['data']=train['description']\n",
    "        train_bunch['target']=train['winery']\n",
    "        train_bunch['price']=train['price']\n",
    "    \n",
    "        return test_bunch,train_bunch\n",
    "    \n",
    "    test_bunch={'data':[],'target':[],'price':[]}\n",
    "    train_bunch={'data':[],'target':[],'price':[]}\n",
    "    \n",
    "    test,train=get_train_test(df)\n",
    "    \n",
    "    train_price_array = np.array(train['price'])\n",
    "    train_price_csr_array = sparse.csr_matrix(train_price_array).transpose()\n",
    "    test_price_array = np.array(test['price'])\n",
    "    test_price_csr_array = sparse.csr_matrix(test_price_array).transpose()\n",
    "        \n",
    "    \n",
    "    ## BOW train!!\n",
    "    vectorizer_bow = CountVectorizer(stop_words = 'english') \n",
    "    feature_matrix_bow = vectorizer_bow.fit_transform(train['data']).astype(float) # replace norm_description by your training data\n",
    "    feature_matrix_bow = sparse.hstack((feature_matrix_bow,train_price_csr_array))\n",
    "    # 2-gram train!!!\n",
    "    vectorizer_2grams = TfidfVectorizer(ngram_range = (2,2)) \n",
    "    feature_matrix_2grams = vectorizer_2grams.fit_transform(train['data']).astype(float) # replace norm_description by your training data\n",
    "    feature_matrix_2grams = sparse.hstack((feature_matrix_2grams,train_price_csr_array))\n",
    "    # 3-gram train!!!\n",
    "    vectorizer_3grams = TfidfVectorizer(ngram_range = (3,3)) \n",
    "    feature_matrix_3grams = vectorizer_3grams.fit_transform(train['data']).astype(float) # replace norm_description by your training data\n",
    "    feature_matrix_3grams = sparse.hstack((feature_matrix_3grams,train_price_csr_array))\n",
    "    # for this part, please fit the testdata\n",
    "    feature_matrix_TEST_bow = vectorizer_bow.transform(test['data'])\n",
    "    feature_matrix_TEST_bow = sparse.hstack((feature_matrix_TEST_bow,test_price_csr_array))\n",
    "    feature_matrix_TEST_2grams = vectorizer_2grams.transform(test['data'])\n",
    "    feature_matrix_TEST_2grams = sparse.hstack((feature_matrix_TEST_2grams,test_price_csr_array))\n",
    "    feature_matrix_TEST_3grams = vectorizer_3grams.transform(test['data'])\n",
    "    feature_matrix_TEST_3grams = sparse.hstack((feature_matrix_TEST_3grams,test_price_csr_array))\n",
    "    \n",
    "    return test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of using 2 grams: \n",
      " 0.34543404735062005\n",
      "Accuracy rate of using 3 grams: \n",
      " 0.2961668545659526\n",
      "Accuracy rate of using bag of words: \n",
      " 0.48184892897406983\n",
      "Accuracy rate of using bag of words for training data: \n",
      " 0.9667277726856096\n",
      "Accuracy rate of using 3 grams for training data: \n",
      " 0.9989000916590284\n",
      "Accuracy rate of using 2 grams for training data: \n",
      " 0.9871982890314698\n"
     ]
    }
   ],
   "source": [
    "accuracy_2grams=[]\n",
    "accuracy_3grams=[]\n",
    "accuracy_bow=[]\n",
    "accuracy_train_bow=[]\n",
    "accuracy_train_3grams=[]\n",
    "accuracy_train_2grams=[]\n",
    "\n",
    "from scipy import sparse\n",
    "for i in range (0,10):\n",
    "    test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams=train_test_with_words(df)\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    #Naive Bayes\n",
    "\n",
    "    #using 2 grams\n",
    "    clf_2grams = MultinomialNB(alpha=0.1) \n",
    "    clf_2grams.fit(feature_matrix_2grams, train['target'])\n",
    "    predicted_nb_2grams = clf_2grams.predict(feature_matrix_TEST_2grams)\n",
    "    cm_2grams = metrics.confusion_matrix(test['target'], predicted_nb_2grams)\n",
    "    #Confusion_matrix=pd.DataFrame(data = cm, columns = target_names,index = target_names)\n",
    "    accuracy_2grams.append(metrics.accuracy_score(test['target'], predicted_nb_2grams))\n",
    "    accuracy_train_2grams.append(metrics.accuracy_score(train['target'], clf_2grams.predict(feature_matrix_2grams)))\n",
    "\n",
    "    \n",
    "    #using 3 grams\n",
    "    clf_3grams = MultinomialNB(alpha=0.1) \n",
    "    clf_3grams.fit(feature_matrix_3grams, train['target'])\n",
    "    predicted_nb_3grams = clf_3grams.predict(feature_matrix_TEST_3grams)\n",
    "    cm_3grams = metrics.confusion_matrix(test['target'], predicted_nb_3grams)\n",
    "    accuracy_3grams.append(metrics.accuracy_score(test['target'], predicted_nb_3grams))\n",
    "    accuracy_train_3grams.append(metrics.accuracy_score(train['target'], clf_3grams.predict(feature_matrix_3grams)))\n",
    "\n",
    "    \n",
    "    #using bag of words\n",
    "    clf_bow = MultinomialNB(alpha=0.1) \n",
    "    clf_bow.fit(feature_matrix_bow, train['target'])\n",
    "    predicted_nb_bow = clf_bow.predict(feature_matrix_TEST_bow)\n",
    "    cm_bow = metrics.confusion_matrix(test['target'], predicted_nb_bow)\n",
    "    accuracy_bow.append(metrics.accuracy_score(test['target'], predicted_nb_bow))\n",
    "    accuracy_train_bow.append(metrics.accuracy_score(train['target'], clf_bow.predict(feature_matrix_bow)))\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Accuracy rate of using 2 grams: \\n\", np.mean(list(accuracy_2grams))) \n",
    "print(\"Accuracy rate of using 3 grams: \\n\", np.mean(list(accuracy_3grams))) \n",
    "print(\"Accuracy rate of using bag of words: \\n\", np.mean(list(accuracy_bow))) \n",
    "print(\"Accuracy rate of using bag of words for training data: \\n\", np.mean(list(accuracy_train_bow))) \n",
    "print(\"Accuracy rate of using 3 grams for training data: \\n\", np.mean(list(accuracy_train_3grams))) \n",
    "print(\"Accuracy rate of using 2 grams for training data: \\n\", np.mean(list(accuracy_train_2grams))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of using 2 grams: \n",
      " 0.25050732807215337\n",
      "Accuracy rate of using 3 grams: \n",
      " 0.21792559188275087\n",
      "Accuracy rate of using bag of words: \n",
      " 0.43731679819616687\n",
      "Accuracy rate of using bag of words for training data: \n",
      " 0.9867705468988694\n",
      "Accuracy rate of using 3 grams for training data: \n",
      " 0.7898869538649557\n",
      "Accuracy rate of using 2 grams for training data: \n",
      " 0.7516040329972502\n"
     ]
    }
   ],
   "source": [
    "accuracy_2grams=[]\n",
    "accuracy_3grams=[]\n",
    "accuracy_bow=[]\n",
    "accuracy_train_bow=[]\n",
    "accuracy_train_3grams=[]\n",
    "accuracy_train_2grams=[]\n",
    "for i in range (0,10):\n",
    "    test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams=train_test_with_words(df)\n",
    "    from sklearn import linear_model\n",
    "    \n",
    "    #Logit Regression\n",
    "\n",
    "    #using 2 grams\n",
    "    clf_2grams = linear_model.SGDClassifier(loss='log') \n",
    "    clf_2grams.fit(feature_matrix_2grams, train['target'])\n",
    "    predicted_nb_2grams = clf_2grams.predict(feature_matrix_TEST_2grams)\n",
    "    cm_2grams = metrics.confusion_matrix(test['target'], predicted_nb_2grams)\n",
    "    #Confusion_matrix=pd.DataFrame(data = cm, columns = target_names,index = target_names)\n",
    "    accuracy_2grams.append(metrics.accuracy_score(test['target'], predicted_nb_2grams))\n",
    "    accuracy_train_2grams.append(metrics.accuracy_score(train['target'], clf_2grams.predict(feature_matrix_2grams)))\n",
    "\n",
    "    \n",
    "    #using 3 grams\n",
    "    clf_3grams = linear_model.SGDClassifier(loss='log') \n",
    "    clf_3grams.fit(feature_matrix_3grams, train['target'])\n",
    "    predicted_nb_3grams = clf_3grams.predict(feature_matrix_TEST_3grams)\n",
    "    cm_3grams = metrics.confusion_matrix(test['target'], predicted_nb_3grams)\n",
    "    accuracy_3grams.append(metrics.accuracy_score(test['target'], predicted_nb_3grams))\n",
    "    accuracy_train_3grams.append(metrics.accuracy_score(train['target'], clf_3grams.predict(feature_matrix_3grams)))\n",
    "\n",
    "    \n",
    "    #using bag of words \n",
    "    clf_bow = linear_model.SGDClassifier(loss='log') \n",
    "    clf_bow.fit(feature_matrix_bow, train['target'])\n",
    "    predicted_nb_bow = clf_bow.predict(feature_matrix_TEST_bow)\n",
    "    cm_bow = metrics.confusion_matrix(test['target'], predicted_nb_bow)\n",
    "    accuracy_bow.append(metrics.accuracy_score(test['target'], predicted_nb_bow))\n",
    "    accuracy_train_bow.append(metrics.accuracy_score(train['target'], clf_bow.predict(feature_matrix_bow)))\n",
    "\n",
    "\n",
    "print(\"Accuracy rate of using 2 grams: \\n\", np.mean(list(accuracy_2grams))) \n",
    "print(\"Accuracy rate of using 3 grams: \\n\", np.mean(list(accuracy_3grams))) \n",
    "print(\"Accuracy rate of using bag of words: \\n\", np.mean(list(accuracy_bow))) \n",
    "print(\"Accuracy rate of using bag of words for training data: \\n\", np.mean(list(accuracy_train_bow))) \n",
    "print(\"Accuracy rate of using 3 grams for training data: \\n\", np.mean(list(accuracy_train_3grams))) \n",
    "print(\"Accuracy rate of using 2 grams for training data: \\n\", np.mean(list(accuracy_train_2grams))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of using 2 grams: \n",
      " 0.24193912063134163\n",
      "Accuracy rate of using 3 grams: \n",
      " 0.2142051860202931\n",
      "Accuracy rate of using bag of words: \n",
      " 0.4205186020293123\n",
      "Accuracy rate of using bag of words for training data: \n",
      " 0.9620531622364803\n",
      "Accuracy rate of using 3 grams for training data: \n",
      " 0.8009471432936145\n",
      "Accuracy rate of using 2 grams for training data: \n",
      " 0.7598838985640086\n"
     ]
    }
   ],
   "source": [
    "accuracy_2grams=[]\n",
    "accuracy_3grams=[]\n",
    "accuracy_bow=[]\n",
    "accuracy_train_bow=[]\n",
    "accuracy_train_3grams=[]\n",
    "accuracy_train_2grams=[]\n",
    "for i in range (0,10):\n",
    "    test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams=train_test_with_words(df)\n",
    "    from sklearn import linear_model\n",
    "    \n",
    "    #SVM \n",
    "\n",
    "    #using 2 grams\n",
    "    clf_2grams = linear_model.SGDClassifier(loss='hinge') \n",
    "    clf_2grams.fit(feature_matrix_2grams, train['target'])\n",
    "    predicted_nb_2grams = clf_2grams.predict(feature_matrix_TEST_2grams)\n",
    "    cm_2grams = metrics.confusion_matrix(test['target'], predicted_nb_2grams)\n",
    "    #Confusion_matrix=pd.DataFrame(data = cm, columns = target_names,index = target_names)\n",
    "    accuracy_2grams.append(metrics.accuracy_score(test['target'], predicted_nb_2grams))\n",
    "    accuracy_train_2grams.append(metrics.accuracy_score(train['target'], clf_2grams.predict(feature_matrix_2grams)))\n",
    "\n",
    "    \n",
    "    #using 3 grams\n",
    "    clf_3grams = linear_model.SGDClassifier(loss='hinge') \n",
    "    clf_3grams.fit(feature_matrix_3grams, train['target'])\n",
    "    predicted_nb_3grams = clf_3grams.predict(feature_matrix_TEST_3grams)\n",
    "    cm_3grams = metrics.confusion_matrix(test['target'], predicted_nb_3grams)\n",
    "    accuracy_3grams.append(metrics.accuracy_score(test['target'], predicted_nb_3grams))\n",
    "    accuracy_train_3grams.append(metrics.accuracy_score(train['target'], clf_3grams.predict(feature_matrix_3grams)))\n",
    "\n",
    "    \n",
    "    #using bag of words \n",
    "    clf_bow = linear_model.SGDClassifier(loss='hinge') \n",
    "    clf_bow.fit(feature_matrix_bow, train['target'])\n",
    "    predicted_nb_bow = clf_bow.predict(feature_matrix_TEST_bow)\n",
    "    cm_bow = metrics.confusion_matrix(test['target'], predicted_nb_bow)\n",
    "    accuracy_bow.append(metrics.accuracy_score(test['target'], predicted_nb_bow))\n",
    "    accuracy_train_bow.append(metrics.accuracy_score(train['target'], clf_bow.predict(feature_matrix_bow)))\n",
    "\n",
    "\n",
    "print(\"Accuracy rate of using 2 grams: \\n\", np.mean(list(accuracy_2grams))) \n",
    "print(\"Accuracy rate of using 3 grams: \\n\", np.mean(list(accuracy_3grams))) \n",
    "print(\"Accuracy rate of using bag of words: \\n\", np.mean(list(accuracy_bow))) \n",
    "print(\"Accuracy rate of using bag of words for training data: \\n\", np.mean(list(accuracy_train_bow))) \n",
    "print(\"Accuracy rate of using 3 grams for training data: \\n\", np.mean(list(accuracy_train_3grams))) \n",
    "print(\"Accuracy rate of using 2 grams for training data: \\n\", np.mean(list(accuracy_train_2grams))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
