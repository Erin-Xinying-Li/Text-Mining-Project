{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winery</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Domaine Zind-Humbrecht</td>\n",
       "      <td>Rich gold in color. Broad, layered aromas of v...</td>\n",
       "      <td>90</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Testarossa</td>\n",
       "      <td>Cooked cranberry is spiced with anise, pepperc...</td>\n",
       "      <td>91</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert Mondavi</td>\n",
       "      <td>Pithy, with grapefruit and lemon peel flavors,...</td>\n",
       "      <td>90</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Testarossa</td>\n",
       "      <td>Overly sweet and simple, and something of a di...</td>\n",
       "      <td>85</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robert Mondavi</td>\n",
       "      <td>With rich, sweet blackberry and cocoa flavors,...</td>\n",
       "      <td>87</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   winery                                        description  \\\n",
       "0  Domaine Zind-Humbrecht  Rich gold in color. Broad, layered aromas of v...   \n",
       "1              Testarossa  Cooked cranberry is spiced with anise, pepperc...   \n",
       "2          Robert Mondavi  Pithy, with grapefruit and lemon peel flavors,...   \n",
       "3              Testarossa  Overly sweet and simple, and something of a di...   \n",
       "4          Robert Mondavi  With rich, sweet blackberry and cocoa flavors,...   \n",
       "\n",
       "   points  price  \n",
       "0      90   84.0  \n",
       "1      91   64.0  \n",
       "2      90   20.0  \n",
       "3      85   49.0  \n",
       "4      87   28.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('top_24_winery.csv',index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4435"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html.parser\n",
      "Requirement already satisfied: ply in /anaconda3/lib/python3.6/site-packages (from html.parser) (3.11)\n",
      "Installing collected packages: html.parser\n",
      "Successfully installed html.parser\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pattern3 in /anaconda3/lib/python3.6/site-packages (3.0.0)\n",
      "Requirement already satisfied: pdfminer.six in /anaconda3/lib/python3.6/site-packages (from pattern3) (20181108)\n",
      "Requirement already satisfied: beautifulsoup4 in /anaconda3/lib/python3.6/site-packages (from pattern3) (4.6.0)\n",
      "Requirement already satisfied: cherrypy in /anaconda3/lib/python3.6/site-packages (from pattern3) (18.1.1)\n",
      "Requirement already satisfied: docx in /anaconda3/lib/python3.6/site-packages (from pattern3) (0.2.4)\n",
      "Requirement already satisfied: pdfminer3k in /anaconda3/lib/python3.6/site-packages (from pattern3) (1.3.1)\n",
      "Requirement already satisfied: feedparser in /anaconda3/lib/python3.6/site-packages (from pattern3) (5.2.1)\n",
      "Requirement already satisfied: simplejson in /anaconda3/lib/python3.6/site-packages (from pattern3) (3.16.0)\n",
      "Requirement already satisfied: pycryptodome in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (3.8.1)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (1.11.0)\n",
      "Requirement already satisfied: sortedcontainers in /anaconda3/lib/python3.6/site-packages (from pdfminer.six->pattern3) (1.5.10)\n",
      "Requirement already satisfied: portend>=2.1.1 in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (2.3)\n",
      "Requirement already satisfied: more-itertools in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (4.1.0)\n",
      "Requirement already satisfied: cheroot>=6.2.4 in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (6.5.4)\n",
      "Requirement already satisfied: zc.lockfile in /anaconda3/lib/python3.6/site-packages (from cherrypy->pattern3) (1.4)\n",
      "Requirement already satisfied: Pillow>=2.0 in /anaconda3/lib/python3.6/site-packages (from docx->pattern3) (5.1.0)\n",
      "Requirement already satisfied: lxml in /anaconda3/lib/python3.6/site-packages (from docx->pattern3) (4.2.1)\n",
      "Requirement already satisfied: ply>=3.4 in /anaconda3/lib/python3.6/site-packages (from pdfminer3k->pattern3) (3.11)\n",
      "Requirement already satisfied: pytest>=2.0 in /anaconda3/lib/python3.6/site-packages (from pdfminer3k->pattern3) (3.5.1)\n",
      "Requirement already satisfied: tempora>=1.8 in /anaconda3/lib/python3.6/site-packages (from portend>=2.1.1->cherrypy->pattern3) (1.14)\n",
      "Requirement already satisfied: backports.functools-lru-cache in /anaconda3/lib/python3.6/site-packages (from cheroot>=6.2.4->cherrypy->pattern3) (1.5)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from zc.lockfile->cherrypy->pattern3) (39.1.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (1.5.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (18.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /anaconda3/lib/python3.6/site-packages (from pytest>=2.0->pdfminer3k->pattern3) (0.6.0)\n",
      "Requirement already satisfied: jaraco.functools>=1.20 in /anaconda3/lib/python3.6/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2.0)\n",
      "Requirement already satisfied: pytz in /anaconda3/lib/python3.6/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2018.4)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pyLDAvis in /anaconda3/lib/python3.6/site-packages (2.1.2)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.23.0)\n",
      "Requirement already satisfied: pytest in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (3.5.1)\n",
      "Requirement already satisfied: numexpr in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (2.6.5)\n",
      "Requirement already satisfied: funcy in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.11)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.31.1)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (1.14.3)\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (2.10)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /anaconda3/lib/python3.6/site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /anaconda3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2018.4)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.5.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (39.1.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (18.1.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (4.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /anaconda3/lib/python3.6/site-packages (from pytest->pyLDAvis) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /anaconda3/lib/python3.6/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.0)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Original:   [\"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\", \"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\"] \n",
      "\n",
      "Processed:  ['circus dog plisse skirt jump python large foot long', 'circus dog plisse skirt jump python large foot long']\n"
     ]
    }
   ],
   "source": [
    "%run ./Text_Normalization_Function.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_description = normalize_corpus(df.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW TEXT:  Rich gold in color. Broad, layered aromas of very ripe fruit with hints of sweet smoke, brown sugar, honey and a savory earthy minerality. Full-bodied, bone dry, but richly textured with crisp acidity and a wide palette of flavors, ripe stone fruit, a creamy savory earthiness, sage and a balsamic kick on the finish. Very long length, slightly warm but with a lingering savory, mineral finish.\n",
      "\n",
      "NORMALIZED TEXT:  rich gold color broad layer aroma ripe fruit hint sweet smoke brown sugar honey savory earthy minerality full bodied bone dry richly textured crisp acidity wide palette flavor ripe stone fruit creamy savory earthiness sage balsamic kick finish long length slightly warm linger savory mineral finish\n"
     ]
    }
   ],
   "source": [
    "print('RAW TEXT: ', np.array(df.description)[0])\n",
    "print()\n",
    "print('NORMALIZED TEXT: ', norm_description[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description']=norm_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Domaine Zind-Humbrecht', 'Testarossa', 'Robert Mondavi',\n",
       "       'Louis Latour', 'Undurraga', 'Chehalem', 'Iron Horse', 'Foxen',\n",
       "       'Chateau Ste. Michelle', 'Wines & Winemakers', 'Georges Duboeuf',\n",
       "       'Maryhill', 'Fess Parker', 'Santa Ema', 'Kendall-Jackson',\n",
       "       'Williams Selyem', 'Concha y Toro', 'Trapiche',\n",
       "       'Feudi di San Gregorio', 'Louis Jadot', 'Bründlmayer',\n",
       "       'DFJ Vinhos', 'V. Sattui', 'Columbia Crest', 'Montes',\n",
       "       'Casa Santos Lima', 'Jean-Luc and Paul Aegerter',\n",
       "       'Chanson Père et Fils', 'Lynmar', 'Siduri', 'Kunde',\n",
       "       'Gary Farrell', 'Albert Bichot'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names=df['winery'].unique()\n",
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please seperate the data into test dataset and training dataset up to this point.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_with_words(df):\n",
    "    def get_train_test(df):\n",
    "        test=df.sample(n=887, replace=False,axis=0)\n",
    "        test_bunch['data']=test['description']\n",
    "        test_bunch['target']=test['winery']\n",
    "        train=df.drop(axis=0, index=test.index)\n",
    "        train_bunch['data']=train['description']\n",
    "        train_bunch['target']=train['winery']\n",
    "    \n",
    "        return test_bunch,train_bunch\n",
    "    test_bunch={'data':[],'target':[]}\n",
    "    train_bunch={'data':[],'target':[]}\n",
    "    test,train=get_train_test(df)\n",
    "    \n",
    "    ## BOW train!!\n",
    "    vectorizer_bow = CountVectorizer(stop_words = 'english') \n",
    "    feature_matrix_bow = vectorizer_bow.fit_transform(train['data']).astype(float) # replace norm_description by your training data\n",
    "    \n",
    "    # 2-gram train!!!\n",
    "    vectorizer_2grams = TfidfVectorizer(ngram_range = (2,2)) \n",
    "    feature_matrix_2grams = vectorizer_2grams.fit_transform(train['data']).astype(float) # replace norm_description by your training data\n",
    "    \n",
    "    # 3-gram train!!!\n",
    "    vectorizer_3grams = TfidfVectorizer(ngram_range = (3,3)) \n",
    "    feature_matrix_3grams = vectorizer_3grams.fit_transform(train['data']).astype(float) # replace norm_description by your training data\n",
    "    \n",
    "    # for this part, please fit the testdata\n",
    "    feature_matrix_TEST_bow = vectorizer_bow.transform(test['data'])\n",
    "    feature_matrix_TEST_2grams = vectorizer_2grams.transform(test['data'])\n",
    "    feature_matrix_TEST_3grams = vectorizer_3grams.transform(test['data'])\n",
    "    \n",
    "    return test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of using 2 grams: \n",
      " 0.37440811724915446\n",
      "Accuracy rate of using 3 grams: \n",
      " 0.29255918827508454\n",
      "Accuracy rate of using bag of words: \n",
      " 0.46674182638105977\n"
     ]
    }
   ],
   "source": [
    "accuracy_2grams=[]\n",
    "accuracy_3grams=[]\n",
    "accuracy_bow=[]\n",
    "for i in range (0,10):\n",
    "    test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams=train_test_with_words(df)\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    #Naive Bayes\n",
    "\n",
    "    #using 2 grams\n",
    "    clf_2grams = MultinomialNB(alpha=0.1) \n",
    "    clf_2grams.fit(feature_matrix_2grams, train['target'])\n",
    "    predicted_nb_2grams = clf_2grams.predict(feature_matrix_TEST_2grams)\n",
    "    cm_2grams = metrics.confusion_matrix(test['target'], predicted_nb_2grams)\n",
    "    #Confusion_matrix=pd.DataFrame(data = cm, columns = target_names,index = target_names)\n",
    "    accuracy_2grams.append(metrics.accuracy_score(test['target'], predicted_nb_2grams))\n",
    "    \n",
    "    #using 3 grams\n",
    "    clf_3grams = MultinomialNB(alpha=0.1) \n",
    "    clf_3grams.fit(feature_matrix_3grams, train['target'])\n",
    "    predicted_nb_3grams = clf_3grams.predict(feature_matrix_TEST_3grams)\n",
    "    cm_3grams = metrics.confusion_matrix(test['target'], predicted_nb_3grams)\n",
    "    accuracy_3grams.append(metrics.accuracy_score(test['target'], predicted_nb_3grams))\n",
    "    \n",
    "    #using bag of words\n",
    "    clf_bow = MultinomialNB(alpha=0.1) \n",
    "    clf_bow.fit(feature_matrix_bow, train['target'])\n",
    "    predicted_nb_bow = clf_bow.predict(feature_matrix_TEST_bow)\n",
    "    cm_bow = metrics.confusion_matrix(test['target'], predicted_nb_bow)\n",
    "    accuracy_bow.append(metrics.accuracy_score(test['target'], predicted_nb_bow))\n",
    "\n",
    "print(\"Accuracy rate of using 2 grams: \\n\", np.mean(list(accuracy_2grams))) \n",
    "print(\"Accuracy rate of using 3 grams: \\n\", np.mean(list(accuracy_3grams))) \n",
    "print(\"Accuracy rate of using bag of words: \\n\", np.mean(list(accuracy_bow))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of using 2 grams: \n",
      " 0.36820744081172496\n",
      "Accuracy rate of using 3 grams: \n",
      " 0.2732807215332581\n",
      "Accuracy rate of using bag of words: \n",
      " 0.4167981961668546\n"
     ]
    }
   ],
   "source": [
    "accuracy_2grams=[]\n",
    "accuracy_3grams=[]\n",
    "accuracy_bow=[]\n",
    "for i in range (0,10):\n",
    "    test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams=train_test_with_words(df)\n",
    "    from sklearn import linear_model\n",
    "    \n",
    "    #Logit Regression\n",
    "\n",
    "    #using 2 grams\n",
    "    clf_2grams = linear_model.SGDClassifier(loss='log') \n",
    "    clf_2grams.fit(feature_matrix_2grams, train['target'])\n",
    "    predicted_nb_2grams = clf_2grams.predict(feature_matrix_TEST_2grams)\n",
    "    cm_2grams = metrics.confusion_matrix(test['target'], predicted_nb_2grams)\n",
    "    #Confusion_matrix=pd.DataFrame(data = cm, columns = target_names,index = target_names)\n",
    "    accuracy_2grams.append(metrics.accuracy_score(test['target'], predicted_nb_2grams))\n",
    "    \n",
    "    #using 3 grams\n",
    "    clf_3grams = linear_model.SGDClassifier(loss='log') \n",
    "    clf_3grams.fit(feature_matrix_3grams, train['target'])\n",
    "    predicted_nb_3grams = clf_3grams.predict(feature_matrix_TEST_3grams)\n",
    "    cm_3grams = metrics.confusion_matrix(test['target'], predicted_nb_3grams)\n",
    "    accuracy_3grams.append(metrics.accuracy_score(test['target'], predicted_nb_3grams))\n",
    "    \n",
    "    #using bag of words \n",
    "    clf_bow = linear_model.SGDClassifier(loss='log') \n",
    "    clf_bow.fit(feature_matrix_bow, train['target'])\n",
    "    predicted_nb_bow = clf_bow.predict(feature_matrix_TEST_bow)\n",
    "    cm_bow = metrics.confusion_matrix(test['target'], predicted_nb_bow)\n",
    "    accuracy_bow.append(metrics.accuracy_score(test['target'], predicted_nb_bow))\n",
    "\n",
    "print(\"Accuracy rate of using 2 grams: \\n\", np.mean(list(accuracy_2grams))) \n",
    "print(\"Accuracy rate of using 3 grams: \\n\", np.mean(list(accuracy_3grams))) \n",
    "print(\"Accuracy rate of using bag of words: \\n\", np.mean(list(accuracy_bow))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of using 2 grams: \n",
      " 0.39481397970687715\n",
      "Accuracy rate of using 3 grams: \n",
      " 0.2939120631341601\n",
      "Accuracy rate of using bag of words: \n",
      " 0.3996617812852311\n"
     ]
    }
   ],
   "source": [
    "accuracy_2grams=[]\n",
    "accuracy_3grams=[]\n",
    "accuracy_bow=[]\n",
    "for i in range (0,10):\n",
    "    test,train,feature_matrix_bow,feature_matrix_2grams,feature_matrix_3grams,feature_matrix_TEST_bow,feature_matrix_TEST_2grams,feature_matrix_TEST_3grams=train_test_with_words(df)\n",
    "    from sklearn import linear_model\n",
    "    \n",
    "    #SVM \n",
    "\n",
    "    #using 2 grams\n",
    "    clf_2grams = linear_model.SGDClassifier(loss='hinge') \n",
    "    clf_2grams.fit(feature_matrix_2grams, train['target'])\n",
    "    predicted_nb_2grams = clf_2grams.predict(feature_matrix_TEST_2grams)\n",
    "    cm_2grams = metrics.confusion_matrix(test['target'], predicted_nb_2grams)\n",
    "    #Confusion_matrix=pd.DataFrame(data = cm, columns = target_names,index = target_names)\n",
    "    accuracy_2grams.append(metrics.accuracy_score(test['target'], predicted_nb_2grams))\n",
    "    \n",
    "    #using 3 grams\n",
    "    clf_3grams = linear_model.SGDClassifier(loss='hinge') \n",
    "    clf_3grams.fit(feature_matrix_3grams, train['target'])\n",
    "    predicted_nb_3grams = clf_3grams.predict(feature_matrix_TEST_3grams)\n",
    "    cm_3grams = metrics.confusion_matrix(test['target'], predicted_nb_3grams)\n",
    "    accuracy_3grams.append(metrics.accuracy_score(test['target'], predicted_nb_3grams))\n",
    "    \n",
    "    #using bag of words \n",
    "    clf_bow = linear_model.SGDClassifier(loss='hinge') \n",
    "    clf_bow.fit(feature_matrix_bow, train['target'])\n",
    "    predicted_nb_bow = clf_bow.predict(feature_matrix_TEST_bow)\n",
    "    cm_bow = metrics.confusion_matrix(test['target'], predicted_nb_bow)\n",
    "    accuracy_bow.append(metrics.accuracy_score(test['target'], predicted_nb_bow))\n",
    "\n",
    "print(\"Accuracy rate of using 2 grams: \\n\", np.mean(list(accuracy_2grams))) \n",
    "print(\"Accuracy rate of using 3 grams: \\n\", np.mean(list(accuracy_3grams))) \n",
    "print(\"Accuracy rate of using bag of words: \\n\", np.mean(list(accuracy_bow))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
